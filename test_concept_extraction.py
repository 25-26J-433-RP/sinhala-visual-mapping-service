"""
Comprehensive test and analysis of concept extraction improvements.
"""

from intelligent_mindmap_generator import IntelligentMindMapGenerator
from nlp_engine import SinhalaNLPEngine
import json

def analyze_concept_extraction():
    """Analyze the quality of concept extraction."""
    nlp = SinhalaNLPEngine()
    gen = IntelligentMindMapGenerator()
    
    # Test cases with expected key concepts
    test_cases = [
        {
            'name': 'Photosynthesis',
            'text': '''
            à¶´à·Šâ€à¶»à¶·à·à·ƒà¶‚à·à·Šà¶½à·šà·‚à¶«à¶º à·à·à¶š à·€à·’à·ƒà·’à¶±à·Š à¶†à·„à·à¶» à¶±à·’à¶´à¶¯à·€à¶± à¶šà·Šâ€à¶»à·’à¶ºà·à·€à¶½à·’à¶ºà¶ºà·’. 
            à¶šà·Šà¶½à·à¶»à·œà¶´à·Šà¶½à·à·ƒà·Šà¶§à·Š à¶­à·”à·… à·ƒà·’à¶¯à·” à·€à¶± à¶¸à·™à¶¸ à¶šà·Šâ€à¶»à·’à¶ºà·à·€à¶½à·’à¶º à·ƒà·–à¶»à·Šà¶º à¶†à¶½à·à¶šà¶º, à¶¢à¶½à¶º à·ƒà·„ à¶šà·à¶¶à¶±à·Š à¶©à¶ºà·œà¶šà·Šà·ƒà¶ºà·’à¶©à·Š à¶·à·à·€à·’à¶­à· à¶šà¶»à¶ºà·’.
            à¶œà·Šà¶½à·–à¶šà·à·ƒà·Š à·ƒà·„ à¶”à¶šà·Šà·ƒà·’à¶¢à¶±à·Š à¶±à·’à¶´à¶¯à·€à¶ºà·’. à·à·à¶šà·€à¶½ à·à¶šà·Šà¶­à·’ à¶¸à·–à¶½à¶º à¶¸à·™à¶º à¶º.
            ''',
            'expected_concepts': ['à¶´à·Šâ€à¶»à¶·à·à·ƒà¶‚à·à·Šà¶½à·šà·‚à¶«à¶º', 'à·à·à¶š', 'à¶šà·Šà¶½à·à¶»à·œà¶´à·Šà¶½à·à·ƒà·Šà¶§à·Š', 'à¶œà·Šà¶½à·–à¶šà·à·ƒà·Š', 'à¶”à¶šà·Šà·ƒà·’à¶¢à¶±à·Š', 'à·ƒà·–à¶»à·Šà¶º à¶†à¶½à·à¶šà¶º', 'à·à¶šà·Šà¶­à´¿']
        },
        {
            'name': 'Water Cycle',
            'text': '''
            à¶¢à¶½ à¶ à¶šà·Šâ€à¶»à¶º à·€à·à¶­à¶»à¶«à¶º, à¶à¶±à·“à¶šà¶»à¶«à¶º à·ƒà·„ à¶…à·€à·ƒà·à¶¯à¶±à¶º à¶‡à¶­à·”à·…à·” à¶šà¶»à¶ºà·’.
            à·ƒà·–à¶»à·Šà¶º à¶­à·à¶´à¶º à¶¸à¶Ÿà·’à¶±à·Š à¶¢à¶½à¶º à·€à·à¶­à·”à¶½à¶ºà¶§ à¶´à¶»à·’à·€à¶»à·Šà¶­à¶±à¶º à·€à·š.
            à·€à·à¶­à·”à·€à·š à¶¢à¶½à¶º à·ƒà·’à·ƒà·’à¶½à·Š à·€à·– à·€à·’à¶§ à¶à¶±à·“à¶šà¶»à¶«à¶º à¶‡à¶­à·’à·€à·š.
            à·€à·ƒà·Šà¶­à·Šâ€à¶» à·ƒà·„ à¶¸à·’à·à·Šâ€à¶» à¶à¶±à·“à¶šà¶»à¶«à¶ºà·™à¶±à·Š à·€à·à·ƒà·’ à·€à·à¶§à·š.
            ''',
            'expected_concepts': ['à¶¢à¶½ à¶ à¶šà·Šâ€à¶»à¶º', 'à·€à·à¶­à¶»à¶«à¶º', 'à¶à¶±à·“à¶šà¶»à¶«à¶º', 'à¶…à·€à·ƒà·à¶¯à¶±à¶º', 'à·€à·ƒà·Šà¶­à·Šâ€à¶»', 'à·€à·à·ƒà·’']
        },
        {
            'name': 'Cell Structure',
            'text': '''
            à¶šà·à· à¶¢à·“à·€à·’à¶­à¶ºà·š à¶¸à·–à¶½ à¶’à¶šà¶š à·€à·š.
            í•µ, à·ƒà¶ºà·’à¶§à·œà¶´à·Šà¶½à´¾à·ƒà·Šà¶¸ à·ƒà·„ à¶´à¶§à·’à¶šà¶º à¶šà·à·à·€à¶½ à¶´à·Šâ€à¶»à¶°à·à¶± à¶šà·œà¶§à·ƒà·Šà¶º.
            à¶´à·™à·… à¶šà·à·à·€à¶½ à¶šà·Šà¶½à·à¶»à·œà¶´à·Šà¶½à·à·ƒà·Šà¶§à·Š, à¶¸à·’à¶­à·à¶šà·œà¶±à·Šà¶©à·Šâ€à¶»à·’à¶ºà· à·ƒà·„ à¶…à¶±à·™à¶šà·”à¶­à·Š à¶‰à¶‚à¶œà·’à¶­à¶º à¶‡à¶­.
            à·ƒà¶­à·”à·€à¶½ à¶šà·à·à·€à¶½ à¶šà·™à¶§à·’ à¶œà·”à¶«à¶‰à¶‚à¶œà·’à¶­à·€à¶­à·”à¶±à·Š à¶­à·’à¶¶à·™à¶ºà·’.
            ''',
            'expected_concepts': ['à¶šà·à·', 'í•µ', 'à·ƒà¶ºà·’à¶§à·œà¶´à·Šà¶½à·à·ƒà·Šà¶¸', 'à¶´à¶§à·’à¶šà¶º', 'à¶šà·Šà¶½à·à¶»à·œà¶´à·Šà¶½à·à·ƒà·Šà¶§à·Š', 'à¶¸à·’à¶­à·à¶šà·œà¶±à·Šà¶©à·Šâ€à¶»à·’à¶ºà·']
        }
    ]
    
    print("=" * 70)
    print("CONCEPT EXTRACTION ANALYSIS")
    print("=" * 70)
    
    all_results = {}
    
    for test_case in test_cases:
        print(f"\nðŸ“š Test: {test_case['name']}")
        print("-" * 70)
        
        # Extract entities
        entities = nlp.extract_entities(test_case['text'])
        print(f"\nExtracted {len(entities)} entities:")
        for i, entity in enumerate(entities[:8]):
            cleaned = nlp.clean_label(entity['text'])
            print(f"  {i+1}. '{entity['text']}' â†’ '{cleaned}' (importance: {entity['importance']:.2f})")
        
        # Extract key phrases
        key_phrases = nlp.extract_key_phrases(test_case['text'], max_phrases=8)
        print(f"\nExtracted {len(key_phrases)} key phrases:")
        for i, (phrase, score) in enumerate(key_phrases[:8]):
            cleaned = nlp.clean_label(phrase)
            print(f"  {i+1}. '{phrase}' â†’ '{cleaned}' (score: {score:.2f})")
        
        # Generate mind map
        result = gen.generate(test_case['text'], {'max_nodes': 15})
        print(f"\nGenerated mindmap with {len(result['nodes'])} nodes:")
        
        concept_nodes = []
        for node in result['nodes']:
            if node['level'] > 0 and node['label']:  # Exclude root
                concept_nodes.append(node['label'])
                if len(concept_nodes) <= 8:
                    print(f"  {len(concept_nodes)}. [{node['type']}] {node['label']}")
        
        # Check coverage of expected concepts
        all_extracted = ' '.join(concept_nodes).lower()
        covered = []
        missed = []
        
        for concept in test_case['expected_concepts']:
            if concept.lower() in all_extracted:
                covered.append(concept)
            else:
                missed.append(concept)
        
        print(f"\nExpected Concepts Coverage:")
        print(f"  âœ“ Covered: {len(covered)}/{len(test_case['expected_concepts'])}")
        if covered:
            for c in covered[:5]:
                print(f"    â€¢ {c}")
        if missed:
            print(f"  âœ— Missed: {len(missed)}/{len(test_case['expected_concepts'])}")
            for m in missed[:3]:
                print(f"    â€¢ {m}")
        
        all_results[test_case['name']] = {
            'total_nodes': len(result['nodes']),
            'coverage': len(covered),
            'total_expected': len(test_case['expected_concepts']),
            'coverage_rate': len(covered) / len(test_case['expected_concepts']) if test_case['expected_concepts'] else 0
        }
    
    # Summary
    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    total_coverage_rate = sum(r['coverage_rate'] for r in all_results.values()) / len(all_results)
    print(f"\nOverall Coverage Rate: {total_coverage_rate*100:.1f}%")
    print("\nDetailed Results:")
    for test_name, result in all_results.items():
        rate = result['coverage_rate'] * 100
        print(f"  {test_name}: {result['coverage']}/{result['total_expected']} concepts ({rate:.0f}%)")

def test_phrase_quality():
    """Test the quality of phrase extraction."""
    nlp = SinhalaNLPEngine()
    
    print("\n\n" + "=" * 70)
    print("PHRASE QUALITY ANALYSIS")
    print("=" * 70)
    
    text = '''
    à¶´à¶»à·’à·ƒà¶» à·€à·’à¶¯à·Šâ€à¶ºà·à·€ à¶´à§ƒà¦¥à·’à·€à·’à¶º à·ƒà·„ à¶‘à·„à·’ à¶¢à·“à·€à·’ à¶œà·€à·šà·‚à¶« à¶šà¶»à¶ºà·’.
    à¶´à·Šâ€à¶»à·à¶«à·’ à·„à· à·à·à¶š à¶‘à¶šà·Š à·ƒà·’à¶§ à¶‘à¶šà·Š à¶…à·€à¶½à¶¸à·Šà¶¶à¶±à¶º à·€à·š.
    à·ƒà·žà¶» à·à¶šà·Šà¶­à·’à¶º à·ƒà·’à¶ºà¶½à·” à¶¢à·“à·€à¶± à¶‰à¶­à·’à¶»à·’à¶º à¶¸à·–à¶½à¶º à·€à·š.
    à·€à·’à¶±à·à· à·ƒà·’à¶šà·Šà¶½ à¶‘ à·à¶šà·Šà¶­à·’à¶º à¶±à·à·€à¶­ à¶¶à·™à¶¯à· à·„à¶»à·’à¶º.
    '''
    
    phrases = nlp.extract_key_phrases(text, max_phrases=15)
    
    print(f"\nExtracted {len(phrases)} phrases:")
    for i, (phrase, score) in enumerate(phrases):
        cleaned = nlp.clean_label(phrase)
        is_stop_phrase = nlp._is_stop_phrase(phrase)
        status = "âš  STOP" if is_stop_phrase else "âœ“ GOOD"
        print(f"  {i+1}. [{status}] '{phrase[:50]}' â†’ '{cleaned[:50]}' (score: {score:.2f})")

if __name__ == '__main__':
    analyze_concept_extraction()
    test_phrase_quality()
