import pytest

from mindmap_generator import SinhalaMindMapGenerator


@pytest.fixture()
def gen():
    return SinhalaMindMapGenerator()


def test_zero_width_joiner_handled(gen):
    # Contains zero-width joiner and non-visible characters
    text = "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì\u200D‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä\u200D ‡∑É‡∑î‡∂±‡∑ä‡∂Ø‡∂ª‡∂∫‡∑í. ‡∂ë‡∂∫ ‡∑Ä‡∑ô‡∂ª‡∑Ö‡∂∫‡∑í."
    res = gen.generate(text)
    assert isinstance(res, dict)
    assert res['nodes'] and res['metadata']['total_nodes'] > 0


def test_punctuation_variants_sentence_splitting(gen):
    text = "‡∂∏‡∑ô‡∂∫ ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∂´‡∂∫‡∂ö‡∑í: ‡∂ë‡∂∫ ‡∑Ä‡∑ê‡∂© ‡∂ö‡∂ª‡∂∫‡∑í! ‡∂ö‡∑ô‡∂ß‡∑í‡∂∫? ‡∂±‡∑í‡∂∫‡∂∏‡∂∫‡∑í‡•§ ‡∂Ö‡∂±‡∑ä‡∂≠‡∑í‡∂∏‡∂∫‡∑í"
    sentences = gen._split_into_sentences(text)
    # Expect several sentences and no very short fragments
    assert len(sentences) >= 3
    assert all(len(s) > 5 for s in sentences)


def test_abbreviation_does_not_produce_short_fragments(gen):
    # '‡∑Å‡∑ä‚Äç‡∂ª‡∑ì.' is a common abbreviation; ensure short fragments are filtered out
    text = "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì. ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä ‡∂Ø‡∑í‡∑Ä‡∂∫‡∑í‡∂±‡∂ö‡∑í. ‡∂ë‡∂∫ ‡∑É‡∑î‡∂±‡∑ä‡∂Ø‡∂ª‡∂∫‡∑í."
    sentences = gen._split_into_sentences(text)
    # The short '‡∑Å‡∑ä‚Äç‡∂ª‡∑ì' fragment should be filtered (length <=5)
    assert all(len(s) > 5 for s in sentences)


def test_long_text_generation_stable(gen):
    # Very long input (repeated sentences) should not create excessive nodes
    sentence = "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä ‡∑É‡∑î‡∂±‡∑ä‡∂Ø‡∂ª‡∂∫‡∑í. "
    long_text = sentence * 5000
    res = gen.generate(long_text)
    # Implementation creates limited hierarchical nodes per paragraph, so expect node count small
    assert res['metadata']['total_nodes'] < 1000


def test_nonstandard_whitespace_and_zero_width_spaces(gen):
    text = "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì\u200B ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä\t‡∂Ø‡∂ö‡∑î‡∂´‡∑î\n‡∂Ü‡∑É‡∑í‡∂∫‡∑è‡∑Ä‡∑ö ‡∂¥‡∑Ä‡∂≠‡∑ì. ‡∂ë‡∂∫ ‡∑É‡∑î‡∂±‡∑ä‡∂Ø‡∂ª‡∂∫‡∑í."
    res = gen.generate(text)
    assert res['metadata']['total_nodes'] > 0


def test_mixed_language_and_urls_and_emojis(gen):
    text = "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä is beautiful. Visit http://example.com üòä. ‡∂ë‡∂∫ ‡∑É‡∑î‡∂±‡∑ä‡∂Ø‡∂ª‡∂∫‡∑í."
    res = gen.generate(text)
    # Ensure generator handles mixed-language input and truncates labels appropriately
    for n in res['nodes']:
        assert 'label' in n
        assert len(n['label']) <= 80  # root truncation uses 80 by default


def test_complex_keyphrase_splitting(gen):
    sentence = "‡∂∏‡∑ô‡∂∫ (‡∑É‡∑í‡∂≠‡∑î‡∑Ä‡∑í‡∂Ω‡∑í), ‡∑É‡∑Ñ ‡∂Ö‡∂Ç‡∑Å, ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫; ‡∂≠‡∑Ä‡∂≠‡∑ä ‡∂ö‡∑ú‡∂ß‡∑É"
    phrases = gen._extract_key_phrases(sentence)
    # Should extract at least one meaningful phrase, respecting length bounds
    assert len(phrases) >= 1
    for p in phrases:
        assert 10 <= len(p) <= 50
